{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Telco Customer Churn - Supervised Learning Project","metadata":{}},{"cell_type":"markdown","source":"# 1. Project Topic\n\nIn this project we want to build a supervised machine learning model that is able to predict whether a customer of a telecommunication company is going to churn or not. This is a classification task with two potential outcomes. To achieve this, we are working with a public dataset from Kaggle that is not part of a competition which means there is no pre-specified evaluation metric. Since the optimal evaluation metric can depend on the structure of our dataset, we will first perform an exploratory data analysis and get to know our data. By leveraging our insights we can then decide which metric might be the best.","metadata":{}},{"cell_type":"markdown","source":"# 2. Project Goal\n\nChurn, within a business context, refers to the loss of a previously acquired customer who has the potential to generate profit. The specific definition of churn may vary across industries. For instance, in the healthcare industry, customers who are deceased are considered churned, whereas in the finance sector, individuals with inactive credit cards are classified as churned.\n\nRetaining an existing customer is more cost-effective than acquiring a new one. Therefore, preventing customer churn is crucial for maintaining a consistent revenue stream. By building a model that is able to predict churn we could save our company a lot of money. We are also interested in which factors have the biggest impact on a customer to churn. By knowning this, we might be able to implement new business strategies that help us retain our customers.","metadata":{}},{"cell_type":"markdown","source":"# 3. Data\n\nThe project is based on the following public Kaggle dataset: https://www.kaggle.com/datasets/blastchar/telco-customer-churn\n\nThe dataset has a tabular format and has multiple columns:\n\n* Churn - Customers who left within the last month\n* Phone, internet, online security, online backup, etc. - Services that each customer has signed up for\n* Contract information, payment method, monthly charges, total charges, etc. - Customer account information\n* Gender, age, etc. - Demographic information about customers","metadata":{}},{"cell_type":"markdown","source":"# 4. Import Python Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport lightgbm as lgb\nimport scipy.stats as stats\nimport optuna\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\nfrom sklearn.metrics import classification_report\nfrom imblearn.over_sampling import SMOTE\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-20T16:16:53.827868Z","iopub.execute_input":"2023-05-20T16:16:53.828297Z","iopub.status.idle":"2023-05-20T16:16:53.837350Z","shell.execute_reply.started":"2023-05-20T16:16:53.828260Z","shell.execute_reply":"2023-05-20T16:16:53.836195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Exploratory Data Analysis\n\n## 5.1 Data Description","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv')","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:17:00.707286Z","iopub.execute_input":"2023-05-20T16:17:00.707684Z","iopub.status.idle":"2023-05-20T16:17:00.780207Z","shell.execute_reply.started":"2023-05-20T16:17:00.707652Z","shell.execute_reply":"2023-05-20T16:17:00.779122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:17:02.336528Z","iopub.execute_input":"2023-05-20T16:17:02.336943Z","iopub.status.idle":"2023-05-20T16:17:02.386510Z","shell.execute_reply.started":"2023-05-20T16:17:02.336914Z","shell.execute_reply":"2023-05-20T16:17:02.385166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:17:05.444708Z","iopub.execute_input":"2023-05-20T16:17:05.445073Z","iopub.status.idle":"2023-05-20T16:17:05.508153Z","shell.execute_reply.started":"2023-05-20T16:17:05.445046Z","shell.execute_reply":"2023-05-20T16:17:05.506926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"numerical_features = ['tenure', 'MonthlyCharges', 'TotalCharges']\ncategorical_features = ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines',\n                        'InternetService','OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', \n                        'StreamingTV', 'StreamingMovies', 'Contract','PaperlessBilling', 'PaymentMethod']","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:17:09.002820Z","iopub.execute_input":"2023-05-20T16:17:09.003467Z","iopub.status.idle":"2023-05-20T16:17:09.009770Z","shell.execute_reply.started":"2023-05-20T16:17:09.003431Z","shell.execute_reply":"2023-05-20T16:17:09.008341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We are working with a dataset of 7043 rows and 21 columns. The last column contains the labeled output value 'Churn' that indicates whether a customer has churned or not. We can also see that there are a lot of categorical variables and only a few numerical variables. As the ouput of the above commands shows the file size is approximately 1.1MB which is quite small, so we don't have to worry about special techniques for handling large file sizes.","metadata":{}},{"cell_type":"markdown","source":"## 5.2 Data Cleaning\n\n### 5.2.1 Missing Values\n\nFirst, we check for NA or NULL values using the built-in functions of pandas dataframes.","metadata":{}},{"cell_type":"code","source":"df.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:18:56.377654Z","iopub.execute_input":"2023-05-20T16:18:56.378057Z","iopub.status.idle":"2023-05-20T16:18:56.427724Z","shell.execute_reply.started":"2023-05-20T16:18:56.378029Z","shell.execute_reply":"2023-05-20T16:18:56.426450Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:18:59.924864Z","iopub.execute_input":"2023-05-20T16:18:59.925263Z","iopub.status.idle":"2023-05-20T16:18:59.974594Z","shell.execute_reply.started":"2023-05-20T16:18:59.925233Z","shell.execute_reply":"2023-05-20T16:18:59.973446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finally, we can also search for empty (or just spaces) string values. ","metadata":{}},{"cell_type":"code","source":"np.where(df.applymap(lambda x: str(x).strip() == ''))","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:19:02.342545Z","iopub.execute_input":"2023-05-20T16:19:02.342965Z","iopub.status.idle":"2023-05-20T16:19:02.429979Z","shell.execute_reply.started":"2023-05-20T16:19:02.342934Z","shell.execute_reply":"2023-05-20T16:19:02.428712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We observe no NA or NULL values but 11 empty strings or spaces in the 'TotalCharges' column. Such empty values make no sense inside a column where we would expect numerical values. In order to handle those empty values there are several commonly used strategies:\n\n* Impute missing values based on their distribution\n* Drop rows with empty values\n* Use advanced imputation techniques (e.g. regression imputation)\n\nWe will start by looking at the distribution of the valid values.","metadata":{}},{"cell_type":"markdown","source":"In order to visualize the valid values of the 'TotalCharges' column we need to filter out the missing values first and convert the datatype to float64.","metadata":{}},{"cell_type":"code","source":"def visualize_totalcharges(df):        \n    plt.hist(df_filtered['TotalCharges'], bins=20)\n    plt.xlabel('Value')\n    plt.ylabel('Frequency')\n    plt.title('Histogram of TotalCharges')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:20:28.917962Z","iopub.execute_input":"2023-05-20T16:20:28.918391Z","iopub.status.idle":"2023-05-20T16:20:28.924425Z","shell.execute_reply.started":"2023-05-20T16:20:28.918361Z","shell.execute_reply":"2023-05-20T16:20:28.923546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# first filter out empty values\ndf_filtered = df[df['TotalCharges'].astype(str).str.strip() != '']\n# then convert to numeric datatype\ndf_filtered.loc[:, 'TotalCharges'] = pd.to_numeric(df_filtered['TotalCharges']).astype('float64')","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:20:35.134616Z","iopub.execute_input":"2023-05-20T16:20:35.135008Z","iopub.status.idle":"2023-05-20T16:20:35.159582Z","shell.execute_reply.started":"2023-05-20T16:20:35.134980Z","shell.execute_reply":"2023-05-20T16:20:35.158609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_totalcharges(df_filtered)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:20:38.179613Z","iopub.execute_input":"2023-05-20T16:20:38.180012Z","iopub.status.idle":"2023-05-20T16:20:38.479111Z","shell.execute_reply.started":"2023-05-20T16:20:38.179982Z","shell.execute_reply":"2023-05-20T16:20:38.478007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The distribution is positively skewed which means we cannot simly impute the mean value. The shape looks more like an exponential distribution. We will check this using the Kolmogorov-Smirnov test. This test makes no assumption about the distribution of data. It can be used to compare a sample with a reference probability distribution which is an exponential in our case.","metadata":{}},{"cell_type":"code","source":"# perform the Kolmogorov-Smirnov test\ndata = df_filtered['TotalCharges'].tolist()\n_, p_value = stats.kstest(data, 'expon')\nprint(\"P-value of Kolmogorov-Smirnov test: \", p_value)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:21:02.963700Z","iopub.execute_input":"2023-05-20T16:21:02.964101Z","iopub.status.idle":"2023-05-20T16:21:02.974248Z","shell.execute_reply.started":"2023-05-20T16:21:02.964072Z","shell.execute_reply":"2023-05-20T16:21:02.972996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In addition, we can also inspect visually if our data originates from an exponential distribution by creating a QQ-Plot.","metadata":{}},{"cell_type":"code","source":"stats.probplot(data, dist='expon', plot=plt)\nplt.title('Q-Q Plot')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:21:11.409845Z","iopub.execute_input":"2023-05-20T16:21:11.411165Z","iopub.status.idle":"2023-05-20T16:21:11.702837Z","shell.execute_reply.started":"2023-05-20T16:21:11.411112Z","shell.execute_reply":"2023-05-20T16:21:11.701661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We observe a good match with the exponential distribution in the lower quantiles. However, for higher quantiles we don't have an exponential shape anymore. This is also reflected by the p-value of the Kolmogorov-Smirnov test. Assuming a typical significance level of 0.05, the p-value of 0 (which is rounded here) signals that the underlying distribution is indeed not an exponential one.\n\nSince it is really hard to guess the exact distribution, we cannot easily fill the missing values with statistical measures like mean oder median at this point. There are two options left how we can proceed from here.\n\n* Drop rows with empty values\n* Use advanced imputation techniques\n\nWe are dealing with only 11 empty values in contrast to over 7000 entries in our dataset. As a first step, we will simply drop them since they make up only such a small part of the whole data. But of course, we should keep in mind that there might be room for improvement here.\n\nFrom this point on, we will work with the **df_filtered** dataset where we already removed the rows containing missing values and converted to the correct datatype.","metadata":{}},{"cell_type":"markdown","source":"### 5.2.2 Inspecting numerical features\n\nNext, we will inspect the numerical features and check whether there are any outliers present in the data.","metadata":{}},{"cell_type":"code","source":"df_filtered.info()","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:24:43.482777Z","iopub.execute_input":"2023-05-20T16:24:43.484054Z","iopub.status.idle":"2023-05-20T16:24:43.535951Z","shell.execute_reply.started":"2023-05-20T16:24:43.484008Z","shell.execute_reply":"2023-05-20T16:24:43.534953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"First, we print out the dataset information and see that we correctly removed some entries. For our numerical features we plot histograms which allow us to easily recognize the distribution and detect any potential outliers. ","metadata":{}},{"cell_type":"code","source":"def visualize_numerical_features(df):\n    \n    fig,axes=plt.subplots(1,3, figsize=(15, 3))\n\n    ax = sns.histplot(df_filtered['tenure'].values, ax=axes[0]).set_title('tenure')\n    ax = sns.histplot(df_filtered['MonthlyCharges'].values, ax=axes[1]).set_title('MonthlyCharges')\n    ax = sns.histplot(df_filtered['TotalCharges'].values, ax=axes[2]).set_title('TotalCharges')","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:25:03.213544Z","iopub.execute_input":"2023-05-20T16:25:03.214191Z","iopub.status.idle":"2023-05-20T16:25:03.220920Z","shell.execute_reply.started":"2023-05-20T16:25:03.214157Z","shell.execute_reply":"2023-05-20T16:25:03.219692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_numerical_features(df_filtered)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:25:05.103200Z","iopub.execute_input":"2023-05-20T16:25:05.104306Z","iopub.status.idle":"2023-05-20T16:25:05.967498Z","shell.execute_reply.started":"2023-05-20T16:25:05.104257Z","shell.execute_reply":"2023-05-20T16:25:05.966354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Our numerical features do not have any outliers. Most of our customers seem to have either really low or high tenure values. That means there are many newly acquired customers and also many that stayed for at least 70 month with the company. The monthly and total charges are both positively skewed which implicates that most of customers are charged with relatively small amounts. At this point it seems likely that monthly and total charges are correlated to each other since the latter one might be calculated based on the former one. Therefore, we will have a look at the correlation matrix.","metadata":{}},{"cell_type":"code","source":"# Calculate correlation matrix for numerical columns\ncorr_matrix = df_filtered[numerical_features].corr()\n\n# Visualize correlation matrix using a heatmap\nsns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\nplt.title('Correlation Matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:25:40.619822Z","iopub.execute_input":"2023-05-20T16:25:40.620957Z","iopub.status.idle":"2023-05-20T16:25:40.937095Z","shell.execute_reply.started":"2023-05-20T16:25:40.620915Z","shell.execute_reply":"2023-05-20T16:25:40.935707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As the heatmap shows, tenure and total charges are highly positively correlated. As suspected earlier, there is also a noticable correlation between monthly and total charges. Since these correlations can impact our model performance we have to think about different strategies to handle them.\n\nWe could use techniques like Principal Component Analysis, Regularization or Feature Selection to fix this problem. But as a first step we will build our model without handling the correlation and see how it performs. Again, we should keep in mind that using one of those methods might yield an improvement in model performance.","metadata":{}},{"cell_type":"markdown","source":"### 5.2.3 Inspecting categorical features\n\nIn this step, we will have a look at the categorical features by creating countplots using seaborn. We will see how the different categories are encoded and if we have to clean things up.","metadata":{}},{"cell_type":"code","source":"def visualize_categorical_features(df):\n    \n    fig,axes=plt.subplots(4,4, figsize=(15, 30))\n    axes = axes.flatten()\n    \n    for i in range(len(categorical_features)):\n        ax = sns.countplot(x=categorical_features[i], data=df, ax=axes[i], hue='Churn')","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:28:33.124635Z","iopub.execute_input":"2023-05-20T16:28:33.125058Z","iopub.status.idle":"2023-05-20T16:28:33.131777Z","shell.execute_reply.started":"2023-05-20T16:28:33.125028Z","shell.execute_reply":"2023-05-20T16:28:33.130359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_categorical_features(df_filtered)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:28:35.164472Z","iopub.execute_input":"2023-05-20T16:28:35.164885Z","iopub.status.idle":"2023-05-20T16:28:38.567184Z","shell.execute_reply.started":"2023-05-20T16:28:35.164854Z","shell.execute_reply":"2023-05-20T16:28:38.566307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are many things to notice in the plots. For example, customers with month-to-month contracts churn more often than those with yearly contracts. The flexibility that the company offers their customers with those short contract durations will likely attract more people but also makes them stay less longer with the company. Another insight we get is that customers using a fiber optic for the internet service are more likely to churn than those who use DSL. As a company we could try to convince more people to switch to DSL in order to reduce customer churn.\n\nOverall, we observe quite an incosistent encoding of the categorical values. For building our model it makes sense to have a consistent and standardized encoding that we will apply now. We also recode the output column 'Churn' from 'Yes' and 'No' to 1 and 0 values.","metadata":{}},{"cell_type":"code","source":"df_final = df_filtered.copy()\nle = LabelEncoder()\n\nfor f in categorical_features :\n    df_final[f] = le.fit_transform(df_final[f])\n    print(f,' : ',df_final[f].unique(),' = ',le.inverse_transform(df_final[f].unique()))\n    \ndf_final['Churn'] = le.fit_transform(df_final['Churn'])\nprint('Churn',' : ',df_final['Churn'].unique(),' = ',le.inverse_transform(df_final['Churn'].unique()))","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:30:14.496122Z","iopub.execute_input":"2023-05-20T16:30:14.496864Z","iopub.status.idle":"2023-05-20T16:30:14.571892Z","shell.execute_reply.started":"2023-05-20T16:30:14.496823Z","shell.execute_reply":"2023-05-20T16:30:14.570752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_categorical_features(df_final)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:30:17.895231Z","iopub.execute_input":"2023-05-20T16:30:17.895742Z","iopub.status.idle":"2023-05-20T16:30:20.891495Z","shell.execute_reply.started":"2023-05-20T16:30:17.895701Z","shell.execute_reply":"2023-05-20T16:30:20.890351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This looks much cleaner. Finally, we perform a one-hot encoding creating dummy variables out of the categorical features and also drop the 'customerID' column since it adds no value to our model.","metadata":{}},{"cell_type":"code","source":"df_final = pd.get_dummies(df_final, columns = categorical_features, drop_first=True)\ndf_final.drop('customerID', axis=1, inplace=True)\ndf_final.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:30:32.451072Z","iopub.execute_input":"2023-05-20T16:30:32.451469Z","iopub.status.idle":"2023-05-20T16:30:32.497499Z","shell.execute_reply.started":"2023-05-20T16:30:32.451440Z","shell.execute_reply":"2023-05-20T16:30:32.496129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.3 Feature Importance\n\nIt might also be worth looking at the importance of different features for our model. This could help us decide which features could be dropped to further increasing model performance. Since the plan is to work with tree-based models we have the advantage that models like Random Forest or Gradient Boosting provide a built-in feature importance measure. We will have a look at this in a few moments. Maybe we will recognize that one of our highly correlated features (Tenure, MonthlyCharges, TotalCharges) is less relevant and can be dropped in order to automatically solve the correlation problem. ","metadata":{}},{"cell_type":"markdown","source":"## 5.4 Investigating Imbalance\n\nAs a last step before building our model we have to investigate our dataset for potential imbalance since this plays a huge role in deciding which evaluation metric to choose.","metadata":{}},{"cell_type":"code","source":"def calculate_imbalance(df):\n    \n    churns = len(df.loc[df['Churn'] == 1])\n    no_churns = len(df.loc[df['Churn'] == 0])\n    \n    # calculate the ratios\n    imbalance_ratio = no_churns / churns\n    churn_ratio = churns / (churns + no_churns)\n    \n    print(\"Imbalance ratio:\", round(imbalance_ratio, 3))\n    print(\"Ratio of churns:\", round(churn_ratio, 3))\n    ","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:33:41.684953Z","iopub.execute_input":"2023-05-20T16:33:41.685413Z","iopub.status.idle":"2023-05-20T16:33:41.692534Z","shell.execute_reply.started":"2023-05-20T16:33:41.685378Z","shell.execute_reply":"2023-05-20T16:33:41.691525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize_imbalance(df):\n    \n    churns = len(df.loc[df['Churn'] == 1])\n    no_churns = len(df.loc[df['Churn'] == 0])\n    \n    labels = ['Churn', 'No Churn']\n    values = [churns, no_churns]\n    \n    # create a bar plot\n    plt.bar(labels, values)\n    plt.xlabel(\"Output\")\n    plt.ylabel(\"Count\")\n    plt.title(\"Imbalance of Dataset\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:33:45.043080Z","iopub.execute_input":"2023-05-20T16:33:45.043464Z","iopub.status.idle":"2023-05-20T16:33:45.051294Z","shell.execute_reply.started":"2023-05-20T16:33:45.043435Z","shell.execute_reply":"2023-05-20T16:33:45.049965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"calculate_imbalance(df_final)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:33:48.987912Z","iopub.execute_input":"2023-05-20T16:33:48.988306Z","iopub.status.idle":"2023-05-20T16:33:49.001396Z","shell.execute_reply.started":"2023-05-20T16:33:48.988277Z","shell.execute_reply":"2023-05-20T16:33:49.000070Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_imbalance(df_final)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:33:51.809764Z","iopub.execute_input":"2023-05-20T16:33:51.810376Z","iopub.status.idle":"2023-05-20T16:33:52.019047Z","shell.execute_reply.started":"2023-05-20T16:33:51.810346Z","shell.execute_reply":"2023-05-20T16:33:52.017900Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We find that there are 2,762 times more customers who haven't churn than those who have stayed with the company. In other words, only 26.6% of customers in the given data set churn. This means our dataset is highly imbalanced and we cannot use an evaluation metric like accuracy for model evaluation.\n\nIf we would not deal with this problem we would actually train our model to be biased and to predict 'No Churn' most of the time. We would obtain a model that cannot predict 'Churn' in a reliable way. In fact, there are multiple ways to deal with imbalanced data and prevent biased model performance. A few of them are:\n\n* Resampling (Oversampling / Undersampling)\n* Class Weighting during model building\n* Focus other evaluation metrics\n\nBefore we apply methods like resampling or class weighting we will build our model using the imbalanced data as a first step and focus on the alternative evaluation metrics.\n\nA good choice might be the recall metric in order to avoid too many false-negatives. As it is commonly known, the cost of customer churn is much higher than the cost to retain the same customer. Therefore false-negatives will have much worse impact on the business than a few false positives.","metadata":{}},{"cell_type":"markdown","source":"# 6. Model Building\n\nFor this classification task we will focus on logistic regression and tree-based models since they are very flexible yet still provide good explainability. We will try out different models, inspect how they perform on our dataset and compare them to each other. The models we will use are:\n\n* Logistic Regression\n* Random Forest\n* Light GBM\n\nBesides the first two commonly known models we will also try out a more sophisticated model called Light GBM which stands for light gradient-boosting machine, originally developed by Microsoft. This model is based on decision tree algorithms and used for ranking and classification tasks with a focus on performance and scalability.","metadata":{}},{"cell_type":"markdown","source":"## 6.1 Basic Models\n\nFirst, we will split our preprocessed dataset into training and test set and prepare a data structure to store our evaluation metrics for model performance.","metadata":{}},{"cell_type":"code","source":"# split features and target variable\nX = df_final.drop('Churn', axis=1)\ny = df_final['Churn']\n\n# split data into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# store resulting metrics\nmodel_metrics = {'Model': [],\n                 'Precision': [],\n                 'Recall': [],\n                 'F1': [],\n                 'Accuracy': []}","metadata":{"execution":{"iopub.status.busy":"2023-05-20T18:30:50.602125Z","iopub.execute_input":"2023-05-20T18:30:50.602578Z","iopub.status.idle":"2023-05-20T18:30:50.618982Z","shell.execute_reply.started":"2023-05-20T18:30:50.602546Z","shell.execute_reply":"2023-05-20T18:30:50.617905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# stores the model's evaluation metrics\ndef add_model_metrics(model_name, y_test, y_pred):\n    model_metrics['Model'].append(model_name)\n    model_metrics['Precision'].append(precision_score(y_test, y_pred))\n    model_metrics['Recall'].append(recall_score(y_test, y_pred))\n    model_metrics['F1'].append(f1_score(y_test, y_pred))\n    model_metrics['Accuracy'].append(accuracy_score(y_test, y_pred))\n\n# fit a logistic regression model\ndef fit_logreg(model_name, X_train, y_train, X_test, y_test):   \n    logreg_classifier = LogisticRegression()\n    logreg_classifier.fit(X_train, y_train)\n    \n    y_pred = logreg_classifier.predict(X_test)\n    add_model_metrics(model_name, y_test, y_pred)\n    return logreg_classifier\n\n# fit a random forest model\ndef fit_randomforest(model_name, X_train, y_train, X_test, y_test):   \n    rf_classifier = RandomForestClassifier()\n    rf_classifier.fit(X_train, y_train)\n\n    y_pred = rf_classifier.predict(X_test)\n    add_model_metrics(model_name, y_test, y_pred)\n    return rf_classifier\n    \n# fit a light GBM model\ndef fit_lightgbm(model_name, X_train, y_train, X_test, y_test):   \n    gmb_classifier = lgb.LGBMClassifier()\n    gmb_classifier.fit(X_train, y_train)\n\n    y_pred = gmb_classifier.predict(X_test)\n    add_model_metrics(model_name, y_test, y_pred)\n    return gmb_classifier","metadata":{"execution":{"iopub.status.busy":"2023-05-20T18:30:53.141034Z","iopub.execute_input":"2023-05-20T18:30:53.141416Z","iopub.status.idle":"2023-05-20T18:30:53.152507Z","shell.execute_reply.started":"2023-05-20T18:30:53.141388Z","shell.execute_reply":"2023-05-20T18:30:53.151324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fit basic models\nlogreg_classifier = fit_logreg('LR', X_train, y_train, X_test, y_test)\nrf_classifier = fit_randomforest('RF', X_train, y_train, X_test, y_test)\ngmb_classifier = fit_lightgbm('GBM', X_train, y_train, X_test, y_test)\n\n# show results\nprint(pd.DataFrame.from_dict(model_metrics))","metadata":{"execution":{"iopub.status.busy":"2023-05-20T18:30:56.766149Z","iopub.execute_input":"2023-05-20T18:30:56.766560Z","iopub.status.idle":"2023-05-20T18:30:58.534363Z","shell.execute_reply.started":"2023-05-20T18:30:56.766530Z","shell.execute_reply":"2023-05-20T18:30:58.533290Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see from the output table all three models perform really bad at predicting churn. This is probably the result of the highly imbalanced dataset. Our main interest lies on the recall value. In this context, the Light GBM model does the best job having a recall value of around 56%.\n\nWe want to make sure to detect as many customers as possible that are about to churn even if we have some customers in the same group that won't churn. Therefore the recall metric is a good choice for model evaluation. Looking at the values these basic models are not sufficient.","metadata":{}},{"cell_type":"markdown","source":"## 6.2 Oversampling\n\nAt this point we will adress the problem of the imbalanced dataset by oversampling the output class that is underrepresented. We will use the SMOTE library which stands for Synthetic Minority Oversampling Technique. The SMOTE class acts like a data transform object from scikit-learn in that it must be defined and configured, fit on a dataset, then applied to create a new transformed version of the dataset. This library does not simply duplicate examples but rather synthesizes new ones from the minority class.\n\nIn detail, the process begins by randomly selecting an example from the minority class. Then, SMOTE identifies its k nearest neighbors from the same class where one neighbor is randomly chosen. Next, a synthetic example is created by combining the selected example and the chosen neighbor. It does this by drawing a line between the two examples in the feature space. Along this line, a new sample is generated at a randomly selected point. The whole process is repeated multiple times.","metadata":{}},{"cell_type":"code","source":"# create the SMOTE oversampler\noversampler = SMOTE(random_state=42)\n\n# perform oversampling on the cleaned dataset\nX_resampled, y_resampled = oversampler.fit_resample(X, y)\n\nprint(\"Class distribution before oversampling:\")\nprint(y.value_counts())\n\nprint(\"Class distribution after oversampling:\")\nprint(pd.Series(y_resampled).value_counts())\n\n# split data into training and test sets again\nX_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T18:31:00.879275Z","iopub.execute_input":"2023-05-20T18:31:00.879690Z","iopub.status.idle":"2023-05-20T18:31:00.940798Z","shell.execute_reply.started":"2023-05-20T18:31:00.879657Z","shell.execute_reply":"2023-05-20T18:31:00.939702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Our class distribution is now balanced. Let's fit the models again using the new data.","metadata":{}},{"cell_type":"code","source":"# fit oversampled models\nlogreg_classifier = fit_logreg('LR (Oversampled)', X_train, y_train, X_test, y_test)\nrf_classifier = fit_randomforest('RF (Oversampled)', X_train, y_train, X_test, y_test)\ngmb_classifier = fit_lightgbm('GBM (Oversampled)', X_train, y_train, X_test, y_test)\n\n# show results\nprint(pd.DataFrame.from_dict(model_metrics))","metadata":{"execution":{"iopub.status.busy":"2023-05-20T18:31:03.590251Z","iopub.execute_input":"2023-05-20T18:31:03.591250Z","iopub.status.idle":"2023-05-20T18:31:05.659813Z","shell.execute_reply.started":"2023-05-20T18:31:03.591210Z","shell.execute_reply":"2023-05-20T18:31:05.658875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Our evaluation metrics are much better now. All three models have a recall value of roughly 85% which can be seen as pretty good. Both tree models perform nearly the same considering the metrics. Interestingly, even the simple logistic regression model does a good job and even has the highest recall value at this point.","metadata":{}},{"cell_type":"markdown","source":"## 6.3 Feature Importance\n\nLet's see if we can improve model performance even more by dropping some of most irrelevant features from our models. In order to do this, we will inspect the built-in feature importance property of our models that ranks all features according to their importance for the model.","metadata":{}},{"cell_type":"markdown","source":"### 6.3.1 Logistic Regression","metadata":{}},{"cell_type":"code","source":"# Get feature importance\nfeature_importance = abs(logreg_classifier.coef_[0])\n\n# Sort in descending order\nindices = feature_importance.argsort()[::-1]\n\n# Print feature ranking\nfor f in range(X_train.shape[1]):\n    print(f\"{f + 1}. Feature '{df_final.columns[f]}' ({feature_importance[indices[f]]})\")","metadata":{"execution":{"iopub.status.busy":"2023-05-20T18:31:07.815335Z","iopub.execute_input":"2023-05-20T18:31:07.815746Z","iopub.status.idle":"2023-05-20T18:31:07.823389Z","shell.execute_reply.started":"2023-05-20T18:31:07.815714Z","shell.execute_reply":"2023-05-20T18:31:07.822202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 6.3.2 Random Forest","metadata":{}},{"cell_type":"code","source":"# Get the feature importance (absolute value of coefficients)\nfeature_importance = abs(rf_classifier.feature_importances_)\n\n# Sort feature importance in descending order\nindices = feature_importance.argsort()[::-1]\n\n# Print feature ranking\nfor f in range(X_train.shape[1]):\n    print(f\"{f + 1}. Feature '{df_final.columns[f]}' ({feature_importance[indices[f]]})\")","metadata":{"execution":{"iopub.status.busy":"2023-05-20T18:31:11.995525Z","iopub.execute_input":"2023-05-20T18:31:11.996295Z","iopub.status.idle":"2023-05-20T18:31:12.019973Z","shell.execute_reply.started":"2023-05-20T18:31:11.996258Z","shell.execute_reply":"2023-05-20T18:31:12.019053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 6.3.3 Light GBM","metadata":{}},{"cell_type":"code","source":"# Get the feature importance (absolute value of coefficients)\nfeature_importance = abs(gmb_classifier.feature_importances_)\n\n# Sort feature importance in descending order\nindices = feature_importance.argsort()[::-1]\n\n# Print feature ranking\nfor f in range(X_train.shape[1]):\n    print(f\"{f + 1}. Feature '{df_final.columns[f]}' ({feature_importance[indices[f]]})\")","metadata":{"execution":{"iopub.status.busy":"2023-05-20T18:31:14.030838Z","iopub.execute_input":"2023-05-20T18:31:14.032004Z","iopub.status.idle":"2023-05-20T18:31:14.039103Z","shell.execute_reply.started":"2023-05-20T18:31:14.031966Z","shell.execute_reply":"2023-05-20T18:31:14.037932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Even though the absolute value of feature importance differs from model to model, the ranking is basically the same. For all three models, the numerical features are the most important whereas the payment method for example does not seem to play an important role for predicting churn. This means all our numerical features that were correlated with each other are important for the model which is why we won't drop any of them. \n\nTo investigate a potential model improvement and since the ranking is the same for all three models we will try including only the first 20 features for experimental purpose. Here, we will also include feature number 21 'TechSupport_2' because it originates from the same feature as 'TechSupport_1'. ","metadata":{}},{"cell_type":"code","source":"columns_to_drop = ['StreamingTV_1', 'StreamingTV_2', 'StreamingMovies_1', 'StreamingMovies_2', \n                   'Contract_1', 'Contract_2','PaperlessBilling_1', 'PaymentMethod_1', 'PaymentMethod_2']\n\nX_feature_selected = X_resampled.drop(columns_to_drop, axis=1)\ny_feature_selected = y_resampled\n\n# split data into training and test sets again\nX_train, X_test, y_train, y_test = train_test_split(X_feature_selected, y_resampled, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T18:31:16.812758Z","iopub.execute_input":"2023-05-20T18:31:16.813176Z","iopub.status.idle":"2023-05-20T18:31:16.825022Z","shell.execute_reply.started":"2023-05-20T18:31:16.813143Z","shell.execute_reply":"2023-05-20T18:31:16.823952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fit feature selected models\nlogreg_classifier = fit_logreg('LR (Feature Sel. 10)', X_train, y_train, X_test, y_test)\nrf_classifier = fit_randomforest('RF (Feature Sel. 10)', X_train, y_train, X_test, y_test)\ngmb_classifier = fit_lightgbm('GBM (Feature Sel. 10)', X_train, y_train, X_test, y_test)\n\n# show results\nprint(pd.DataFrame.from_dict(model_metrics))","metadata":{"execution":{"iopub.status.busy":"2023-05-20T18:31:20.319874Z","iopub.execute_input":"2023-05-20T18:31:20.320692Z","iopub.status.idle":"2023-05-20T18:31:22.338562Z","shell.execute_reply.started":"2023-05-20T18:31:20.320655Z","shell.execute_reply":"2023-05-20T18:31:22.337489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Dropping the last 10 features had not the effect we hoped for. The recall for Logistic Regression and Random Forest is now even slightly worse than before. Only the Light GBM model improved a little bit. It seems like it is not that easy and there may be hidden relationships that we should not remove whereas each model behaves a little different on its own.\n\nSince the noticed differences were very small overall, we will not follow up any further on this even if a more sophisticated approach might work better here, e.g. a k-fold cross-validation to find the optimal subset of features.\n\nBefore we proceed, we have to roll back our training and test data to the resampled version.","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T18:31:26.287446Z","iopub.execute_input":"2023-05-20T18:31:26.287862Z","iopub.status.idle":"2023-05-20T18:31:26.297824Z","shell.execute_reply.started":"2023-05-20T18:31:26.287832Z","shell.execute_reply":"2023-05-20T18:31:26.296718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6.4 Hyperparameter Tuning\n\nInstead of proceeding with feature selection we will try to improve our model by performing a hyperparameter tuning.\n\nFor our logistic regression model we will tune the 'C' parameter that is used for regularization and therefore for preventing overfitting. For random forest model we will tune typical tree parameters like the maximum depth of the generated trees or the minimum number of samples required to be at a leaf node. Finally, our Light GBM model also has typical tree-based parameters like the maximum depth but also some sepcial ones like the learning rate.\n\nAll best models are selected using grid search and the recall metric as a strategy to evaluate the performance of the cross-validated model on the test set.","metadata":{}},{"cell_type":"code","source":"def fit_logreg_tuning(model_name, X_train, y_train, X_test, y_test):   \n    logreg_classifier = LogisticRegression()\n    \n    # define hyperparameter grid\n    param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n    grid_search = GridSearchCV(logreg_classifier, param_grid, scoring='recall', cv=3)\n    grid_search.fit(X_train, y_train)\n    \n    # get best hyperparameters and model\n    best_params = grid_search.best_params_\n    best_model = grid_search.best_estimator_\n    print(\"Best parameters for Logistic Regression:\", best_params)\n    \n    # predict\n    y_pred = best_model.predict(X_test)\n    add_model_metrics(model_name, y_test, y_pred)\n    \n    return best_model, best_params\n    \ndef fit_randomforest_tuning(model_name, X_train, y_train, X_test, y_test):   \n    rf_classifier = RandomForestClassifier()\n    \n    # define hyperparameter grid\n    param_grid = {\n        'n_estimators': [100,200,300,400],\n        'max_depth': [10, 13, 17, 20],\n        'min_samples_leaf': [2,3,4],\n        'min_samples_split': [2,5,10],\n        'max_features': ['sqrt', 'auto']\n    }\n    grid_search = GridSearchCV(rf_classifier, param_grid, scoring='recall', cv=3)\n    grid_search.fit(X_train, y_train)\n    \n    # get best hyperparameters and model\n    best_params = grid_search.best_params_\n    best_model = grid_search.best_estimator_\n    print(\"Best parameters for Random Forest:\", best_params)\n    \n    # predict\n    y_pred = best_model.predict(X_test)\n    add_model_metrics(model_name, y_test, y_pred)\n    \n    return rf_classifier, best_params\n    \ndef fit_lightgbm_tuning(model_name, X_train, y_train, X_test, y_test):   \n    gmb_classifier = lgb.LGBMClassifier()\n    \n    # define hyperparameter grid\n    param_grid = {\n        'n_estimators': [500,600,700,800],\n        'max_depth': [5, 10, 15],\n        'learning_rate': [0.10, 0.15, 0.20],\n        'min_child_weight': [1],\n        'colsample_bytree': [0.5]\n    }\n    grid_search = GridSearchCV(estimator=gmb_classifier, param_grid=param_grid, scoring='recall', cv=3)\n    grid_search.fit(X_train, y_train)\n    \n    # get best hyperparameters and score\n    best_params = grid_search.best_params_\n    best_score = grid_search.best_score_\n    print(\"Best parameters for Light GBM:\", best_params)\n    \n    # train the LightGBM classifier with the best parameters\n    best_lgbm = lgb.LGBMClassifier(**best_params)\n    best_lgbm.fit(X_train, y_train)\n    \n    # predict\n    y_pred = best_lgbm.predict(X_test)\n    add_model_metrics(model_name, y_test, y_pred)\n        \n    return gmb_classifier, best_params","metadata":{"execution":{"iopub.status.busy":"2023-05-20T18:31:29.825905Z","iopub.execute_input":"2023-05-20T18:31:29.826296Z","iopub.status.idle":"2023-05-20T18:31:29.846881Z","shell.execute_reply.started":"2023-05-20T18:31:29.826268Z","shell.execute_reply":"2023-05-20T18:31:29.845694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fit hyperparameter tuned models\nlogreg_classifier, lr_best_params = fit_logreg_tuning('LR (Hyp. tuned)', X_train, y_train, X_test, y_test)\nrf_classifier, rf_best_params = fit_randomforest_tuning('RF (Hyp. tuned)', X_train, y_train, X_test, y_test)\ngmb_classifier, gmb_best_params = fit_lightgbm_tuning('GBM (Hyp. tuned)', X_train, y_train, X_test, y_test)\n\n# show results\nprint(pd.DataFrame.from_dict(model_metrics))","metadata":{"execution":{"iopub.status.busy":"2023-05-20T18:31:36.418365Z","iopub.execute_input":"2023-05-20T18:31:36.418788Z","iopub.status.idle":"2023-05-20T19:04:44.767349Z","shell.execute_reply.started":"2023-05-20T18:31:36.418757Z","shell.execute_reply":"2023-05-20T19:04:44.766226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The output shows the best selected parameters for each model. Overall, the hyperparameter tuning did not have a huge impact on the model scores. Some of the metrics even got worse. We will discuss these final results in the next part.","metadata":{}},{"cell_type":"markdown","source":"# 7. Results and Analysis\n\n## 7.1 Evaluation Metrics\n\nAs already mentioned, in the context of our business it has to be the highest priority to detect as many customers as possible that are about to churn even if we also classify some some customers as 'likely to churn' even if that is not true (false positive). Therefore the recall metric is a good choice for model evaluation. Other possible options would be a balanced accuracy that accounts for the actual number of positive and negative samples or the F1 score that is the harmonic mean of precision and recall.\n\nLet's print the evaluation metrics of all of our models in a clean looking table format.","metadata":{}},{"cell_type":"code","source":"model_metrics_df = pd.DataFrame.from_dict(model_metrics)\nmodel_metrics_df","metadata":{"execution":{"iopub.status.busy":"2023-05-20T19:05:13.277301Z","iopub.execute_input":"2023-05-20T19:05:13.277736Z","iopub.status.idle":"2023-05-20T19:05:13.297423Z","shell.execute_reply.started":"2023-05-20T19:05:13.277703Z","shell.execute_reply":"2023-05-20T19:05:13.296665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Using the basic models yielded poor results due to the imbalanced dataset. Performing oversampling on the minority output class resulted in a huge improvement across all models whereas the logistic regression model performed best when only looking at the recall score. Next, we inspected feature importance and tried to remove the least important ones. Here, our models behaved quite differently. The performance of logistic regression and random forest became worse whereas light GBM slightly improved. Due to these mixed and negligible effects we rolled back to our oversampled dataset and performed a final hyperparameter tuning. Compared to the values after oversampling recall of logistic regression and light GBM did not change much whereas recall of random forest made the most significant jump up to a value of around 87%.","metadata":{}},{"cell_type":"markdown","source":"## 7.2 Model Performance and Visualization\n\nWe can now plot a ranking of all our models accoring to their recall value.","metadata":{}},{"cell_type":"code","source":"# sort by recall value\nmodel_metrics_df_sorted = model_metrics_df.sort_values(by='Recall', ascending=False)\n\n# plot the ranking\nplt.figure(figsize=(8, 6))\nplt.barh(model_metrics_df_sorted['Model'], model_metrics_df_sorted['Recall'], color='b')\nplt.xlabel('Recall')\nplt.ylabel('Model')\nplt.title('Ranking of Recall-Name Pairs')\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-20T19:05:16.903812Z","iopub.execute_input":"2023-05-20T19:05:16.904191Z","iopub.status.idle":"2023-05-20T19:05:17.219475Z","shell.execute_reply.started":"2023-05-20T19:05:16.904163Z","shell.execute_reply":"2023-05-20T19:05:17.218603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And we see our final and best model considering the recall metric would be Random Forest with the following set of parameters.","metadata":{}},{"cell_type":"code","source":"pd.DataFrame.from_dict(rf_best_params, orient='index', columns=['Value'])","metadata":{"execution":{"iopub.status.busy":"2023-05-20T19:10:10.541785Z","iopub.execute_input":"2023-05-20T19:10:10.542757Z","iopub.status.idle":"2023-05-20T19:10:10.551903Z","shell.execute_reply.started":"2023-05-20T19:10:10.542721Z","shell.execute_reply":"2023-05-20T19:10:10.551156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 8. Conclusion\n\nAs a final step in this project let's talk about what did work out well and where things could be improved.","metadata":{}},{"cell_type":"markdown","source":"## 8.1 Learnings and Takeaways\n\nRunning through a machine learning project from start to finish really shows how crucial the preparation steps like data cleaning and preparation are for model building. As we have seen, imputing missing values can be very difficult depending on the underlying data distribution. There can be also complex and hidden relationships between the data and the different models (and parameters) that make certain model improvement techniques not work out as we have seen with the feature importance. And finally, for classification tasks an imbalanced dataset can occur very often in real-world scenarios like this and we have to account for it by performing some form of resampling. Additionally, we have to be aware that not all evaluation metrics fit the problem in cases where we suffer from imbalanced data.","metadata":{}},{"cell_type":"markdown","source":"## 8.2 What did not work\n\nImputing missing values for the total charges column did not work as hoped for since our data did not originate from the suspected exponential distribution. Another aspect that did not work as expected was the feature selection process during model building where we tried to remove seemingly irrelevant features. By doing so, we could not achieve significant performance improvement but made some models even worse than before.","metadata":{}},{"cell_type":"markdown","source":"## 8.3 Possible Improvements\n\nThe usage of advanced imputation techniques like regression imputation for handling missing values could result in a (slightly) better model performance. We could also apply advanced techniques for optimal feature selection like cross-validation and optimal subset detection instead of just removing the last 10 features as we did during model building. Maybe this could also help us with the problem of correlated features. If not, we should try out other methods like PCA or Regularization. Of course, we should also check the potential correlation between the categorical features in this course.","metadata":{}}]}